##事务原子性

###数据库中的缓存db_buffer、持久化文件data file
###日志的缓存log_buffer、日志持久化log file

### WAL
一个事务进行。刷到缓存log buffer,进行日志存储(UNDO和REDO)到log file，接着再然后写入db buffer，如果db buffer，最后再由db buffer选择策略写入到Log file。这样就就叫坐预写日志(write ahead log)。

如果log buffer的数量为1，能够保证数据的一致性。一旦有数据就进行持久化。但是如果是多个的话，当出现故障的话，会导致log buffer丢失和data buffer丢失，导致数据无法恢复。不过这种能够提高io吞吐量

### Postgres的导入与导出
    导入：psql -U postgres -p 5432 -d ott-cms -1(数字1) -f xx.sql
    由于之前没有加上-1，导致当执行某一句出错的时候，并没有进行回滚，使用了-1保证一个事务
    问题：导入会出现client的gbk字符集无法正常导入(明明服务端的编码是utf-8，文件也是utf-8)。
    原因：可使用psql进入命令行，show client_encoding的字符集，然后使用了set client_encoding to 'utf8'来设置编码
    问题：文件用ue保存为utf-8，但是却一直导入错误
    原因：大文件使用了utf-16进行保存，可以将其转为utf-8（必须是无bom，bom的前三个字节为efbbbf） 
    导出：使用pg_dump -U xxx -p xxx -n schema -d 数据库 -t 表 --inserts -a（必须加上-a，才是只有数据，没有结构）

### 对于数据库的pg_trgm
   1. pg_trgm是可以进行计算字符串的匹配度，但是对于其的划分规则则是，比如test一个字符串会被切割成t、te、est、st、tes等好几个字符串。
   2. 线上video使用了name gist_trgm_os的方式来新建索引，那么名字这边就会被切割成多个字符串的索引，线上有400多w的数据，那么索引的效率必然不好
   
### coalesce
   返回第一个非Null的值

### 全文索引的一些函数
   1. setweight(tsvector,'A'); //这个可以设置tsvector的权重，比如有几个字段进行全文检索，body、title、description，那么我可以通过setweight(to_tsvector(title), 'A')将title的权重加大
   2. to_rank((float[]),tsvectory,tsquery)，这样来得到匹配分值，float数组就可以设定对应的分支array(0.1,0.2,0.3,0.4)这样来设置分值
   3. ts_query中可以设置权值匹配的方式。比如to_tsquery('天才:A|灌篮:B')。这个方式是为了比如有一句话是"天才灌篮高手是个天才"，我们通过setweight为前面的"天才"设置了权重值为A；又有另外一句话"樱木是个天才"，这里的"天才"权重值设为B，那么通过to_tsquery('天才:A')就只能过滤出第一句话
   
### 视频搜索匹配度排序优化
   思路演变过程：

    1：将现有的视频名称切字存储，采用tsvector分词方式存储，并创建索引，测试检索的效率奇高，但是这样可以满足了模糊匹配，那匹配排序的怎么办？   
    2：对视频名称进行前缀索引的建立，但是postgresql是没有前缀索引，只能是表达式索引，但是后面这种方式直接摒弃了，因为前缀索引也只能满足一个，但是一个视频可能被多个前缀给查询，所以这种方式肯定不符合。但是这种想法肯定是正常的。
    3：采用count(left(name,12))*1.0/count(*)来查看视频名称的前缀索引的有效性。因此对视频名称的采用了1到12个前缀的分词存储在另外一个字段tsvector2，并对tsvector2建立索引，并通过setweight()来设置对应的权值。比如“战狼2”，那么"战"weight为D、"战狼"为B,"战狼2"则为'A'。
       查询的时候，select * from video where tsvector2 @@ '战狼'::tsquery order by to_rank(tsvector2,'战狼'::tsquery) desc limit 10;
       以上来根据搜索匹配的度排序。虽然能达到效果，但是索引巨大，需要2.多G，索引取消。
       前面以为是因为setweight的关系导致索引，后面证实是因为tsvector量太多的关系
    4：细化前缀词，比如有视频名称长度为20多个字甚至更多的字，如果只是因为战狼开头，那么所得到的得分应该也不高。而且根据用户习惯，一个用户如果输入了8-9个字符还没有找到他所想要的视频，那么他肯定不会再继续输入。因为考虑了一下，做了以下抉择：
       4.1 视频名称如果超过9个，不再进行前缀保存。因为关键词已经相当无效.如果需要9个字符之后过滤，量已经足够少了，不需要再进行匹配排序
       4.2 "战"搜索，更希望搜索出以“战”开头的东西，但是两个字匹配、甚至三个字匹配、四个字匹配、五个字匹配已经足够多了，根本没有必要9个字这种视频名称就从一个字开始存储。可以从9-4就是5个字开始存储。
       根据以上规则之后，已经再将关键词细化了
    5：上面的基础上，关键词可能还不太合理，应该添加人工维护的部分。比如名侦探柯南，柯南也是一个关键词，但是需要人工进行区分设置，这样更灵活。

### 对于pg_trgm的研究
    1. 每个单词都可以看作是两个空格前缀、一个空格后缀的组合。
    2. ~模糊匹配看作是取出索引值，再对~之后的正则表达式中提取出对应的trgim值，然后由索引去匹配

### 事务隔离性
    1. 可通过begin transaction isolution level repeatable read; 来设置事务级别
    2. 先进入begin事务中，然后通过set transaction isolution level repeatable read
    3. 可重复读和幻读
       3.1 可重复读：比如事务1 select name from video where id=1; // 查出来是“战狼”
                       事务2 update video set name='战狼2' where id=1; // commit
                       事务1 select name from video where id=1; // 查出来是"战狼2"，与第一次查询出现了不一致。
       3.2 幻读（已有id=1的记录）： 但是必须先经过查找表了，才会对表进行快照。比如事务1 select name from video where id < 3; // 查出来是id=1一条记录。才会对video进行快照
                     事务2 insert into video(id,name)values(2,'战狼');// commit
                     事务1 insert into video(id,name)values(2,'战狼');// 插入失败。但是select出来却没有id=2的数据  
       
### 词典
    1. select * from pg_ts_config; // 查看所有的文本搜索配置
    2. 解析器。
       select * from pg_ts_parser;// 可以查看多少文本解析器；
       select ts_token_type('cfgname') // 可以查看默认有多少个解析器类型；
       pg_ts_config_map;// 表示一个text search config配置了多少解析器类型 
    3. 词典：
    create text search DICTIONARY public.test(template=simple,STOPWORDS=english);
    创建一个词典。模板是simple，停用词是english（停用词的目录在/pg/share/textsearch/english.stop）
    select ts_lexise('public.test','the'); // 如果在停用词中找到了分词，则返回空。


### 分区表
    1. 在创建触发器对应的函数，需要动态插入。 execute 'insert into partition values($1.*)' using NEW;
    2. 在对video做分区表的时候
       2.1 对video表创建对应的分区表->创建对应的触发器->执行函数循环分区表，为每个分区表导入数据。insert into xxx select * from only video where ...；为分区表创建索引->然后truncate table only video;
       2.2 创建video_bk，结构备份(create table video_bk as (select * from video limit 0))->创建video_bk的对应分区->创建触发器->拷贝数据insert into video_bk select * from video(会将数据拷贝到对应的分区表中)->为分区表创建索引->rename 备份表和原表
       



    
   